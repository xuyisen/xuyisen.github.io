---
title: 简单代码克隆检测(程序优化，GPU版本代码的修改)
comment: true
copyright: true
date: 2018-09-07 15:35:04
categories: Scala
tags: clone_detection
---

本周的主要任务是对现有版本的代码进行优化，并通过修改程序代码产生GPU版本的代码，经过试验发现，提速的效果尚可，但不是很明显。  

<!--more-->

## 程序优化背景   

通过之前的实验我们可以发现，程序运行的时间主要发生在`autoencoder`上面，即将词向量转换成句向量的过程。对此我想根据网上的一些方法对这部分代码进行优化，其优化的方法主要有以下几个过程。   

### 多进程执行

在上次开会的时候我们就已经说了，代码已经使用openmpi允许我们多进程并行计算，于是我就简单的测试了多个进程和单个进程执行的时间差异。  

* 2个进程，CPU  
我是在李老师提供的GPU服务器上跑的实验，该实验并没有调用GPU进行加速。  
启动   
![图片描述](/images/115.png)  
开启的两个进程  
![图片描述](/images/116.png)  
未调用GPU   
![图片描述](/images/117.png)  
结果： 跑了80分钟，没跑完，我强行结束了   
![图片描述](/images/118.png) 

*  10个进程，CPU  
同样是在相同的服务器上进行的实验，该实验并没有调用GPU进行加速   
启动  
![图片描述](/images/119.png)  
开启10个进程  
![图片描述](/images/120.png)  
未调用GPU  
结果：  1991s  
![图片描述](/images/121.png)  

* 20个进程，CPU  
启动  
![图片描述](/images/122.png)  
开启20个进程  
![图片描述](/images/123.png)  
未调用GPU  
结果： 1847s   
![图片描述](/images/124.png)    


通过实验可以看出来之后简单的增加的运行的进程已经对速度的提升不太明显，所以之后祭出神器GPU来对我们的代码进行加速。   

###  GPU代码加速   

通过阅读代码发现，该`autoencoder`使用的是Numpy,Scipy来进行的系列的矩阵操作，并没有使用什么TensorFlow类似的神经网络框架，所以并没有现成的GPU版本的框架直接替代，到目前为止有两个方法，一个是将Scipy转为用TensorFlow类似神经网络的框架，但是没有任何实践经验，无从下手，所以我决定在代码内部做点改变，使其支持GPU。具体尝试的方法有以下几种：  

* minpy:  http://www.yueye.org/2017/use-minpy-to-accelerate-numpy.html  ,使用minpy替代Numpy进行矩阵操作，经过试验发现失败了，原因是，minpy只实现了Numpy的部分功能，许多方法并不能支持。   
* Numba:  http://numba.pydata.org/numba-doc/0.39.0/index.html  Numba 是通过加注释的方法直接将Python 里面的一些数组和数学操作编译为本机机器指令，性能类似与C,C++和Fortran,无需切换语言或者python编译器。说的比较神奇，通过官网的介绍感觉也很神奇，加一个注释就可以实现加速然后在GPU上跑，看一个简单的例子：   
![图片描述](/images/125.png)   
然后就做了实验，在我们代码forword的函数上面加了注释，结果报了一堆BUG,什么类型不对，不支持object类型等等，当时改了好久，实在改不下去了，就放弃。实验失败。   
* cupy： https://cupy.chainer.org/  ，cupy 号称是 Numpy的GPU版本，在说明文档里也一直和Numpy比较，还可以实现两种结构数据的转换，做了一点简单的实验，觉得应该可以转换。  

所以最终决定使用cupy替代Numpy,实现GPU支持，当然其中需要修改很多代码，虽然官网说是完全替代，其实并不是。最终经过两天半的不断修改，GPU版本可以运行了，我们看下结果。   

* 4 个进程 GPU  
还是使用李老师给的GPU服务器   
启动  
![图片描述](/images/126.png)   
调用GPU  
![图片描述](/images/128.png)   
结果：  1578s  
![图片描述](/images/131.png)   
这里我们只是用了服务器里面的一块GPU，并没有全部使用，结果看来虽然加速了，但是效果并不是很好啊，就提高了300s,当时我怀疑是服务器配置的问题，以为我开启四个进程，GPU就100%了，所以我决定在贾老师的电脑里试一试。于是又花了一天的时间配置服务器的环境，进行了实验。实验结果如下。    

* 10个进程 GPU  
使用的是贾老师实验室的服务器   
启动  
![图片描述](/images/129.png)   
调用GPU   
![图片描述](/images/130.png)  
结果  ：  909s   
![图片描述](/images/132.png)  
这次实验也只用电脑里面的一块GPU，速度提升可以看到，一半左右，但是也没有达到10倍一百倍那种地步，后期还需要探索问一下相关老师。   

Note: GPU 版本相关代码已经发布到 GitLab上面去了:   http://125.220.157.228/clone_detection/clone_detection_tools_gpu   ，老师可以进行相关测试。   




